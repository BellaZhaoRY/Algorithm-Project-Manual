---
sort: 4
---


# 向量模型训练

* [算法开发手册](https://kg-nlp.github.io/Algorithm-Project-Manual/向量表示/向量模型训练.html)

* [个人知乎](https://www.zhihu.com/people/zhangyj-n)

[TOC]

参考:[向量集合](https://kg-nlp.github.io/Algorithm-Project-Manual/向量表示/向量集合.html)


> Domain-adaptive Pretraining + SimCSE + In-batch Negatives 路线

1. 基础预训练模型->领域预训练模型->领域数据无监督->标注数据获取->领域数据有监督
2. 向量模型->领域数据无监督-标注数据获取->领域数据有监督



### 汇总

* 领域语料 [LLM数据处理](https://kg-nlp.github.io/Algorithm-Project-Manual/大模型/LLM数据处理.html)  建筑领域语料-20230830

* 领域词典  建筑领域词典-20230830.txt

* 总结向量模型基础模型,训练策略,数据域,数据量,数据格式

| 向量模型             | 基础模型                                                 | 数据域        | 数据格式                 | 训练策略                                | 评测策略 |
| -------------------- | -------------------------------------------------------- | ------------- | ------------------------ | --------------------------------------- | -------- |
| Chinese Word Vectors |                                                          |               | 文本,分词列表            | 无监督SGNS/PPMI(ngram)                  |          |
| Text2vec             | ernie,lert,macbert,paraphrase-multilingual-MiniLM-L12-v2 |               | 三元组                   | 有监督ConSENT                           |          |
| uniem                | roberta                                                  | 多领域+指令集 | 句子对,三元组,带分数句对 | 有监督in-batch-negative                 |          |
| FlagEmbedding        | retromae                                                 | 悟道,simclue  | 三元组                   | retormae,in-batch-negative,跨设备负采样 |          |
| RocketQA 系列        | ernie                                                    | 多领域        | 句对,listwise            | 各种负采样,联合训练                     |          |



* **算法**
  * simcse
    * 无监督训练,使用对比学习,利用dropout机制将同一样本过两次模型得到不同的embedding
  * esimcse
    * 随机重复单词构造正例,解决句子长度敏感问题
  * diffcse
    * simcse+electra simcse进行对比学习的同时为判别器提供句向量,electra生成伪样本和RTD任务学习原始句子和伪造句子差异
  * promptbert
    * prompt+对比学习  prompt模型输出mask对应的最后一层hidden state;利用不同模板表征同一句子,然后减去模板信息,进行对比学习
  * retromae
    * 面向检索任务的预训练模型



* **其他**
  * [算法框架-文本匹配-算法汇总（持续更新）](https://zhuanlan.zhihu.com/p/465584667)
  * [代码链接-paddle](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/applications/neural_search/recall)(领域模型+无监督+有监督训练)
  * [SimCSE、ESimCSE、DiffCSE](https://blog.csdn.net/sinat_39620217/article/details/132281318?spm=1001.2014.3001.5502)
  * [DiffCSE](https://zhuanlan.zhihu.com/p/507171467)
  * [中文文本语义匹配-pytorch](https://github.com/shawroad/Semantic-Textual-Similarity-Pytorch)
  * [中文文本语义匹配2](https://github.com/Macielyoung/sentence_representation_matching)
  * [语言模型中文认知能力分析](https://github.com/twang2218/vocab-coverage)







## 自监督训练

### 基于领域模型的无监督学习



### 基于向量模型的无监督学习





## 监督训练

### 标注数据获取

### 基于领域模型的监督学习

### 基于向量模型的监督学习


