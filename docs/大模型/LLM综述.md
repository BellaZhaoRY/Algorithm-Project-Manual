---
sort: 5
---

# LLM综述

## 引言



## 资源汇总
* [Lawyer LLaMA](https://github.com/AndrewZhe/lawyer-llama)
    * [基于chinese-llama-plus北大团队推出法律大模型，数据与模型全部开源，模型合并使用全流程](https://mp.weixin.qq.com/s/WtBwSPZ7jCzJNk3aQVllUQ)
* [中文 LLaMA & OpenLLaMA & Falcon 大模型](https://github.com/CVI-SZU/Linly)
    * [中文Falcon基础模型：代码实现与增量训练](https://zhuanlan.zhihu.com/p/636994073)
* 大模型参数高效微调
    *  [大模型参数高效微调技术原理综述（一）-背景、参数高效微调简介](https://mp.weixin.qq.com/s/P_AmTa4s8dOyc_0fZBgNPA)  
    *  [大模型参数高效微调技术原理综述（二）-BitFit、Prefix Tuning、Prompt Tuning](https://mp.weixin.qq.com/s/fUAUr9X3XLndfjga2QIHbA)
    *  [大模型参数高效微调技术原理综述（三）-P-Tuning、P-Tuning v2](https://mp.weixin.qq.com/s/f4l04f78F507JRrCawnV8w)
    *  [大模型参数高效微调技术原理综述（四）-Adapter Tuning及其变体](https://mp.weixin.qq.com/s/nUAcCz6mcgGuUeuTfgqmOQ)
    *  [大模型参数高效微调技术原理综述（五）-LoRA、AdaLoRA、QLoRA](https://mp.weixin.qq.com/s/N_N6RqKB9pjZ1tozfM5f5A)
    *  [大模型参数高效微调技术原理综述（六）-MAM Adapter、UniPELT](https://mp.weixin.qq.com/s/M2nds_FJBXooi08qDU-4yA)
    *  [大模型参数高效微调技术原理综述（七）-最佳实践、总结](https://mp.weixin.qq.com/s/P_AmTa4s8dOyc_0fZBgNPA)


## 参考 
[1] [A Survey of Large Language Models](https://arxiv.org/abs/2303.18223)  
[2] [A Survey of Large Language Modelsgithub](https://github.com/RUCAIBox/LLMSurvey/tree/main)