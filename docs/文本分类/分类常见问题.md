# 分类常见问题


* [算法开发手册](https://kg-nlp.github.io/Algorithm-Project-Manual/文本分类/分类常见问题.html)

* [个人知乎](https://www.zhihu.com/people/zhangyj-n)



## 高能AI
* [如何解决NLP分类任务的11个关键问题：类别不平衡&低耗时计算&小样本&鲁棒性&测试检验&长文本分类](https://zhuanlan.zhihu.com/p/183852900)
* [韩家炜课题组重磅发文：文本分类只需标签名称，不需要任何标注数据！](https://zhuanlan.zhihu.com/p/345738174)





## 指标问题

### AUC

* 对于分类任务,模型的预测能力和预测结果的评价都是上线前要关注的。

  * 在最近的分类任务中标签共有75个，存在长尾分布，并且训练数据样本极不均衡。

  * 前期使用F1(宏平均)评价多标签分类下模型预测效果，查看各标签的识别结果去优化模型

  * 后期从业务评价角度考虑，只关注了准确率（负样本的概念不存在，说法只有不同标签的样本，所以准确率包含了所有标签的匹配结果）

  * 上面从模型预测结果指标选择模型，只能说预测的好坏，但如果有多个模型预测结果差不多，该选择哪个就成了问题。所以增加AUC指标判断模型对分类任务的区分程度。

* [如何深刻理解 AUC-ROC 曲线](https://zhuanlan.zhihu.com/p/121036836)

  * AUC-ROC曲线是针对**各种阈值设置下的分类问题的性能度量**。ROC是概率曲线，AUC表示可分离的程度或测度，它告诉我们多少模型能够区分类别。

  * AUC值是判断模型区分能力的指标

* [sklearn.metrics.roc_auc_score计算方法](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html)

  * 多分类 计算prob时用的可能是softmax,满足概率和为1;二分类(也可能是softmax)和多标签用的是sigmoid,通过阈值确定

  * 如果使用多分类时,不能写*multi_class='raise'* 

  * `ovr`代表One-vs-rest。计算每个类相对于其他类的AUC,多标签处理也这么设置参数

  * `ovo`代表One-vs-one。计算每个类和所有其他类中的每一类的AUC，最后将AUC和求平均

* 怎么根据ROC曲线,选择最优的阈值(来自ChatGPT)

  ```
  根据ROC曲线选择最优阈值的方法如下：
  
  绘制ROC曲线：首先，使用不同的阈值将模型的预测结果转化为二分类输出（正类和负类）。然后，计算每个阈值下的真正例率（True Positive Rate，TPR）和假正例率（False Positive Rate，FPR），并将其绘制在坐标系中，得到ROC曲线。
  
  计算AUC值：计算ROC曲线下的面积（Area Under the Curve，AUC）。AUC值越大，说明模型的性能越好。
  
  定义最优阈值：根据实际需求和成本效益分析，确定最优的阈值。例如，如果更重视准确率，则可以选择使得FPR较低且TPR较高的阈值；如果更重视召回率，则可以选择使得FPR较高且TPR较低的阈值。
  
  验证最优阈值：使用验证数据集或交叉验证方法，在选择的最优阈值下评估模型的性能，确保最优阈值能够在实际应用中取得较好的效果。
  
  需要注意的是，选择最优阈值并不是一成不变的，它会根据具体问题和实际情况进行调整。因此，在使用ROC曲线选择阈值时，需要综合考虑问题的特点和需求，选择最适合的阈值来平衡模型的性能。
  ```

  * 方法1: 根据不同阈值训练模型,以准确率为指标得到模型,计算各自的auc值,辅助判断模型的区分能力

  * 方法2:定义阈值0.5(通过训练0.4-0.6之间结果差不多),训练模型,绘制roc曲线,计算auc值(判断当前模型的能力作为参考),根据真阳率TPR和假阳率FPR计算最优阈值
  
  * 上面的方法都涉及到:如何计算多分类多标签的auc,roc
  
  * 使用代码确定最优值,多标签多分类效果不太好
  
  * ```python
    # 计算auc值,绘制roc曲线,计算最大阈值
    def get_roc_auc(input_path):
        from sklearn.metrics import roc_curve, auc
        import matplotlib.pyplot as plt
        # 假设y_true是真实标签，y_score是预测得分（概率或决策函数）
        # y_true的形状为 (样本数, 标签数)
        # y_score的形状为 (样本数, 标签数)
        y_true = []
        y_score = []
        @paddle.no_grad()
        def evaluate():
            model, tokenizer = get_model(params_path)
            collate_fn = DataCollatorWithPadding(tokenizer)
            _dataset, _data_loader = get_data_loader(input_path, label2id, collate_fn, tokenizer)
            model.eval()
            for batch in tqdm(_data_loader):
                label = batch.pop("labels")
                logits = model(**batch)
                probs = F.sigmoid(logits).numpy()
                y_true.extend(label)
                y_score.extend(probs)
        evaluate()
    
        y_true = np.array(y_true)
        y_score = np.array(y_score)
        # 计算每个标签的ROC曲线和AUC值
        fpr = {}
        tpr = {}
        thresholds = {}
        roc_auc = {}
        n_classes = y_true.shape[1]  # 标签数
        for i in range(n_classes):
            fpr[i], tpr[i], thresholds[i] = roc_curve(y_true[:, i].ravel(), y_score[:, i].ravel())
            roc_auc[i] = auc(fpr[i], tpr[i])
    
        # 计算微平均ROC曲线（将所有标签的预测结果合并成一个二进制问题）
        fpr["micro"], tpr["micro"], thresholds['micro'] = roc_curve(y_true.ravel(), y_score.ravel())
        roc_auc["micro"] = auc(fpr["micro"], tpr["micro"])
    
        print(fpr['micro'])
    
        # 绘制ROC曲线
        plt.figure()
        # 绘制微平均的ROC曲线
        plt.plot(fpr["micro"], tpr["micro"],
                 label='micro-average ROC curve (area = {0:0.2f})'
                       ''.format(roc_auc["micro"]),
                 color='deeppink', linestyle=':', linewidth=4)
        # 绘制对角线
        plt.plot([0, 1], [0, 1], 'k--', lw=2)
    
        # 设置图形属性
        plt.xlim([0.0, 1.0])
        plt.ylim([0.0, 1.05])
        plt.xlabel('False Positive Rate')
        plt.ylabel('True Positive Rate')
        plt.title('Multi-Label ROC Curve')
        plt.legend(loc="lower right")
        plt.savefig('./v7/image/multi-label-roc-curve.jpg')
        # 显示图形
        plt.show()
    
        # 寻找最优阈值
        # best_thresholds = []
        # for i in range(n_classes):
        #     dist = np.sqrt(np.square(1 - tpr[i]) + np.square(fpr[i]))  # 计算距离
        #     best_index = np.argmin(dist)  # 找到最小距离的索引
        #     best_threshold = thresholds[i][best_index]  # 获取最优阈值
        #     best_thresholds.append(best_threshold)
        best_thresholds = thresholds['micro'][np.argmax(tpr['micro'] - fpr['micro'])]
        print("Best Thresholds:", best_thresholds)
    ```
  
    



* 参考
  * [二分类auc计算](https://blog.csdn.net/pearl8899/article/details/109829306)
  * [多分类auc计算](https://blog.csdn.net/pearl8899/article/details/109830350)
  * [ROC曲线及如何计算AUC](https://blog.csdn.net/u010505915/article/details/106394765)
  * [多分类ROC曲线及AUC计算(*)](https://blog.csdn.net/u010505915/article/details/106450150)
  * [多标签评价指标AUC计算](https://blog.csdn.net/wuli_xin/article/details/129390292)





### 选择最佳模型

